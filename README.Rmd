---
output:
  md_document:
    variant: markdown_github
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```

[![CRAN Version](http://www.r-pkg.org/badges/version/spacyr)](http://cran.r-project.org/package=spacyr) ![Downloads](http://cranlogs.r-pkg.org/badges/spacyr) [![Travis-CI Build Status](https://travis-ci.org/kbenoit/spacyr.svg?branch=master)](https://travis-ci.org/kbenoit/spacyr) [![codecov.io](https://codecov.io/github/kbenoit/spacyr/spacyr.svg?branch=master)](https://codecov.io/github/kbenoit/spacyr/coverage.svg?branch=master)

(note: the Travis build fails because our script does not install spaCy and the English language files - once these are installed, it passes the R Check.)

# spacyr: an R wrapper for spaCy

This package is an R wrapper to the spaCy "industrial strength natural language processing" Python library from http://spacy.io.

### Prerequisites

1.  Python must be installed on your system.  

2.  spaCy must be installed on your system.  Follow [these instructions](http://spacy.io/docs/).

    Installation on Windows:  
    a)  (If you have not yet installed Python:)  Download and install [Python for Windows](https://www.python.org/downloads/windows/).  We recommend the 2.7.12, using (if appropriate) the Windows x86-64 MSI installer.  During the installation process, be sure to scroll down in the installation option window and find the "Add Python.exe to Path", and click on the small red "x."  
    b)  Install spaCy and the English language model using these commands at the command line:  
        ```
        pip install -U spacy
        python -m spacy.en.download
        ```
        For alternative installations or troubleshooting, see the [spaCy docs](https://spacy.io/docs/).  
    c)  Test your installation at the command line using:  
        ```
        python -c "import spacy; spacy.load('en'); print('OK')"
        ```

3.  You need (of course) to install this package:  
    ```{r, eval = FALSE}
    devtools::install_github("kbenoit/spacyr")
    ```


### Examples

The `tag()` function calls spaCy to both tokenize and tag the texts, and returns a special class of tokenizedText object (see [**quanteda**](http://githiub.com/kbenoit/quanteda)) that has both tokens and tags.  The approach to tokenizing taken by spaCy is inclusive: it includes all tokens without restrictions.  The default method for `tag()` is the [Google tagset for parts-of-speech](https://github.com/slavpetrov/universal-pos-tags).

```{r}
require(spacyr)
# find spaCy and set the correct environment variables
initialize_spacy()

# show tag on some sample sentences
head(data_sentences)
taggedsents <- tag(data_sentences[1:6])
taggedsents
```

Note that while the printed structure appears to append the token and its tag, in fact the structure of the object records these separately:
```{r}
str(taggedsents)
```

To get a summary of the parts of speech for each document, use the data.frame returned by the `summary()` method for this new object class:
```{r}
summary(taggedsents)
```

Alternatively the [Penn Treebank](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html) part-of-speech tagset can be applied:
```{r}
taggedsents2 <- tag(data_sentences[1:6], tagset = "penn")
summary(taggedsents2)
```

Many of the standard methods from [**quanteda**](http://githiub.com/kbenoit/quanteda) work on the new tagged token objects:
```{r}
docnames(taggedsents)
ndoc(taggedsents)
ntoken(taggedsents)
ntype(taggedsents)
```


## Comments and feedback

We welcome your comments and feedback.  Please file issues on the issues page, and/or send me comments at kbenoit@lse.ac.uk.

Plans moving ahead include finding much more efficient methods of calling spaCy from R than [the current use of `system2()`](https://github.com/kbenoit/spacyr/blob/master/R/tag.R#L71).


